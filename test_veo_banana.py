#!/usr/bin/env python3
"""
ğŸŒ Banana Dance Test - Phase 2 Veo Agent Testing
Tests the Veo agent with a fun scenario: dancing banana video generation
"""

import asyncio
import json
from datetime import datetime

from app.core.schemas import GeneratedImage, ImagenOutput
from app.agents.veo_agent.agent import VeoAgent


async def create_banana_dance_test():
    """Create a mock banana image and generate a dancing banana video"""
    
    print("\n" + "="*70)
    print("ğŸŒ BANANA DANCE VEO TEST - Phase 2")
    print("="*70)
    
    # Step 1: Create mock Imagen output with a banana dancing image
    print("\nğŸ“¸ Step 1: Creating mock banana image...")
    
    banana_image = GeneratedImage(
        image_id="img_banana_dance",
        slide_number=1,
        local_path="/Users/danielefres/Projects/GTMForge/output/images/banana_dancing_slide_1_0.png",
        url=None,  # Phase 3 will have real GCS URLs
        quality_score=0.95,
        generation_time_seconds=3.2,
        prompt_used="A vibrant yellow banana with a big smile, dancing energetically with musical notes around it. Cinematic lighting, professional photography, bright colors, fun and playful atmosphere, 16:9 aspect ratio",
        refinement_iteration=0
    )
    
    # Create ImagenOutput with the banana image
    imagen_output = ImagenOutput(
        images=[banana_image],
        total_generation_time_seconds=3.2,
        average_quality_score=0.95,
        generation_complete=True,
        errors=[]
    )
    
    print(f"âœ“ Mock image created: {banana_image.prompt_used}")
    print(f"  - Image ID: {banana_image.image_id}")
    print(f"  - Local path: {banana_image.local_path}")
    print(f"  - Quality score: {banana_image.quality_score}")
    
    # Step 2: Initialize Veo Agent
    print("\nğŸ¬ Step 2: Initializing Veo Agent...")
    veo_agent = VeoAgent(quality_threshold=0.80, max_retries=2)
    print(f"âœ“ Veo Agent initialized")
    print(f"  - Quality threshold: {veo_agent.quality_threshold}")
    print(f"  - Max retries: {veo_agent.max_retries}")
    
    # Step 3: Generate video using Veo Agent
    print("\nğŸ¥ Step 3: Generating banana dancing video...")
    print("-" * 70)
    
    try:
        veo_output = await veo_agent.execute(imagen_output)
        
        print("-" * 70)
        print("âœ“ Video generation completed!")
        
        # Step 4: Display results
        print("\nğŸ“Š Step 4: Results")
        print("-" * 70)
        
        if veo_output.videos:
            video = veo_output.videos[0]
            
            print(f"\nâœ“ VIDEO GENERATED:")
            print(f"  - Video ID: {video.video_id}")
            print(f"  - Local path: {video.local_path}")
            print(f"  - Duration: {video.duration_seconds} seconds")
            print(f"  - Quality score: {video.quality_score:.2f}/1.0")
            print(f"  - Generation time: {video.generation_time_seconds:.1f} seconds")
            print(f"  - Source images: {', '.join(video.source_images)}")
            
            print(f"\nğŸ“ˆ STAGE METRICS:")
            print(f"  - Videos generated: {len(veo_output.videos)}")
            print(f"  - Average quality: {veo_output.average_quality_score:.2f}/1.0")
            print(f"  - Total generation time: {veo_output.total_generation_time_seconds:.1f}s")
            print(f"  - Generation complete: {veo_output.generation_complete}")
            print(f"  - Errors: {len(veo_output.errors)}")
            
            if veo_output.errors:
                print(f"\nâš ï¸  ERRORS ENCOUNTERED:")
                for error in veo_output.errors:
                    print(f"  - {error}")
            
            # Phase 2 Reality Check
            print(f"\nâš ï¸  PHASE 2 UPDATE:")
            print(f"  âœ“ Architecture working correctly")
            print(f"  âœ“ Video file IS created at {veo_output.videos[0].local_path}")
            print(f"  âœ“ File is a valid MP4 that can be opened")
            print(f"  âœ— Real Veo API not yet called (Vertex AI API needs enabling on GCP project)")
            print(f"  â†’ Phase 3: Will call actual Veo API for real video generation")
            
            # Summary
            print("\n" + "="*70)
            print("ğŸ‰ TEST SUCCESSFUL - Veo Agent pipeline works!")
            print("="*70)
            
            return {
                "status": "success",
                "video_id": video.video_id,
                "quality_score": video.quality_score,
                "duration": video.duration_seconds,
                "timestamp": datetime.now().isoformat(),
                "phase": "2_mock_testing"
            }
        
        else:
            print("âŒ No videos generated")
            return {"status": "failed", "reason": "No videos in output"}
    
    except Exception as e:
        print(f"\nâŒ ERROR: {str(e)}")
        print(f"Error type: {type(e).__name__}")
        return {"status": "error", "message": str(e)}


def main():
    """Run the banana dance test"""
    print("\nğŸš€ Starting Banana Dance Veo Test...\n")
    
    result = asyncio.run(create_banana_dance_test())
    
    # Save results
    output_file = "/Users/danielefres/Projects/GTMForge/output/banana_dance_test.json"
    with open(output_file, 'w') as f:
        json.dump(result, f, indent=2)
    
    print(f"\nğŸ’¾ Results saved to: {output_file}\n")


if __name__ == "__main__":
    main()
